# âœ… Chapitre 1 â€“ Technologie comme mÃ©moire solidifiÃ©e

## 1.1 Technologie : connaissance rendue opÃ©rationnelle

La technologie nâ€™est pas un **ensemble dâ€™outils**, mais une **forme de connaissance** qui a Ã©tÃ© **rendue utilisable sans Ãªtre comprise**. Cette dÃ©finition, qui peut sembler paradoxale, est pourtant centrale dans lâ€™histoire des techniques. Elle permet de **distinguer la technologie de lâ€™ingÃ©nierie, lâ€™usage de la comprÃ©hension, la diffusion de la maÃ®trise**.

Whitehead (1929) le formulait ainsi :  
> Â« La civilisation avance en Ã©tendant le nombre dâ€™opÃ©rations importantes que nous pouvons effectuer sans y penser. Â»Â¹  

Cette formule nâ€™est pas un Ã©loge de lâ€™ignorance, mais une **thÃ©orie de la mÃ©moire externe**. La technologie est ce qui **stocke une connaissance** dans une **forme matÃ©rielle ou procÃ©durale**, de sorte quâ€™elle **puisse Ãªtre rÃ©utilisÃ©e sans Ãªtre reconnue**. Elle est **une mÃ©moire solidifiÃ©e, une connaissance fossilisÃ©e, une compÃ©tence dÃ©lÃ©guÃ©e**.

En clair : la technologie est une bibliothÃ¨que invisible. Elle nous permet dâ€™agir sans avoir Ã  apprendre tout ce que lâ€™objet contient.  

Philippe Silberzahn rÃ©sume lâ€™idÃ©e en ces termes :  
> Â« La technologie nâ€™est pas un outil que lâ€™on ajoute au monde, câ€™est une mÃ©moire que lâ€™on retire Ã  la tÃªte. Â»â·  

Cette externalisation nâ€™est pas un dÃ©faut : elle est la **condition mÃªme de la division du savoir**. Elle devient un risque lorsque la mÃ©moire externe Ã©chappe Ã  tout contrÃ´le collectif, câ€™est-Ã -dire quand nous ne savons plus ouvrir, lire, rÃ©parer ou refuser lâ€™artefact qui pense Ã  notre place.

**Exemple :**  
Un agriculteur du XVe siÃ¨cle nâ€™a **pas besoin de comprendre la mÃ©canique des sols** pour utiliser une **charrue**. Il **hÃ©rite dâ€™un dispositif** qui encode des siÃ¨cles dâ€™expÃ©rimentation agricole : angle du soc, profondeur de labour, rÃ©sistance au tracÃ©, adaptation aux terrains.Â²  

La **connaissance** est dans lâ€™objet, non dans la tÃªte.  
Cette mÃ©moire externalisÃ©e nâ€™est pas un accident : elle est la **condition anthropologique de lâ€™Homme sapiens augmentÃ©**. Dans son billet Â« Et si lâ€™artificiel Ã©tait notre vraie nature ? Â» (2024), Silberzahn pousse le point plus loin : lâ€™artificiel nâ€™est pas un appendice, il est le **milieu natal dans lequel lâ€™humain se mÃ©tamorphose en permanence**.â¸  

---

## 1.2 De la mÃ©moire incarnÃ©e Ã  la mÃ©moire externe

Dans les sociÃ©tÃ©s orales, la mÃ©moire est **incarnÃ©e**. Elle est dans le geste, dans le rythme, dans le chant, dans le rituel.Â³  

Dans les sociÃ©tÃ©s techniques, la mÃ©moire devient **externe**. Elle est dans lâ€™outil, dans le protocole, dans la machine, dans lâ€™algorithme.  

**Exemple simple :** aujourdâ€™hui, nous ne retenons plus les itinÃ©raires par cÅ“ur. Nous dÃ©lÃ©guons cette mÃ©moire au **GPS**.  

Cette **externalisation** nâ€™est pas neutre. Elle **transforme la nature du savoir**. Elle **dÃ©sindividualise la compÃ©tence**. Elle **dÃ©synchronise lâ€™invention de lâ€™usage**. Elle **dilue la responsabilitÃ©**. Mais elle **augmente la coordination Ã  grande Ã©chelle**.  

Hayek (1945) le montrait dÃ©jÃ  :  
> Â« Le problÃ¨me central de lâ€™Ã©conomie nâ€™est pas lâ€™allocation des ressources, mais lâ€™utilisation de la connaissance dispersÃ©e. Â»â´  

La technologie est ce qui **rÃ©sout ce problÃ¨me en encapsulant la connaissance dans des objets qui la rendent portable, rÃ©plicable, standardisÃ©e**.  

---

## 1.3 Objets physiques vs artefacts sociaux

On peut classer les objets techniques en deux grandes familles :  

| Type | Exemples | Fonction | ComplexitÃ© |
|------|----------|---------|------------|
| Objets physiques | Marteau, machine Ã  expresso, pont | Transformer la matiÃ¨re | Visible (structure, matÃ©riau) |
| Artefacts sociaux | Loi, protocole, algorithme, plateforme | Coordonner les acteurs | Invisible (logique, code, norme) |

Ces deux types partagent une **structure commune** :  
- ils encapsulent une connaissance  
- ils la rendent utilisable sans expertise  
- ils permettent une coordination sans comprÃ©hension totale  

Mais ils ne produisent pas les mÃªmes effets de pouvoir.  
Les objets physiques sont visibles et tangibles, les artefacts sociaux sont invisibles mais tout aussi puissants. Une loi ou un algorithme peut orienter nos vies autant quâ€™un pont ou une machine.  

---

## 1.4 Artefacts sociaux : la technologie devenue invisible

Les **artefacts sociaux** sont des technologies immatÃ©rielles. Ils **rÃ¨glent les interactions entre humains**. Ils **codent des normes, des routines, des attentes**. Ils **produisent de lâ€™ordre sans force physique**.  

**Exemples :**  
- Le **protocole TCP/IP** : routage des paquets sans autoritÃ© centrale  
- Le **code civil** : rÃ¨gle les conflits sans jugement moral  
- Les **algorithmes de recommandations** : orientent lâ€™attention sans intention explicite  

Ces artefacts ne sont pas neutres. Ils **inscrivent dans la durÃ©e des choix politiques dÃ©guisÃ©s en nÃ©cessitÃ©s techniques**.âµ  
Ils **produisent des effets sans responsable identifiable**. Ils deviennent incontournables sans Ãªtre compris.  

**Exemple concret :** un algorithme de recommandation peut influencer des millions de citoyens sans quâ€™aucun dÃ©cideur ne soit identifiÃ© comme responsable.  

---

## 1.5 La dÃ©lÃ©gation comme condition de la division du travail

La **division du travail** nâ€™est pas seulement une division des tÃ¢ches, câ€™est une **division du savoir**.  
Chaque **spÃ©cialitÃ©** encapsule une fraction de connaissance dans un **artefact** (outil, procÃ©dure, norme).  
Cette **encapsulation** permet la coordination sans comprÃ©hension partagÃ©e.  

**Exemple :**  
Un **pilote de ligne** ne comprend pas le moteur de lâ€™avion. Il ne comprend pas le protocole de routage aÃ©rien. Il ne comprend pas le systÃ¨me de rÃ©servation.  
Mais il coordonne lâ€™ensemble de ces savoirs encapsulÃ©s pour faire voler un avion.  

Cette coordination sans comprÃ©hension est la condition de la modernitÃ©.  
Mais elle devient dangereuse quand les artefacts Ã©chappent Ã  tout contrÃ´le collectif.  
Autrement dit : notre sociÃ©tÃ© fonctionne grÃ¢ce Ã  des savoirs dÃ©lÃ©guÃ©s. Mais si personne ne peut auditer ces savoirs, la confiance collective sâ€™effondre.  

---

## 1.6 Le risque de la complexitÃ© opaque

Lorsque la **complexitÃ© interne** dâ€™un artefact dÃ©passe la capacitÃ© collective Ã  lâ€™auditer, lâ€™objet devient **ingouvernable**.  
Il produit des effets sans rÃ©troaction. Il gÃ©nÃ¨re des dÃ©pendances sans garde-fou. Il concentre le pouvoir sans lÃ©gitimitÃ©.  

**Exemple :**  
Le **systÃ¨me financier algorithmique** traite 70 % des transactions boursiÃ¨res en millisecondes.  
Aucun Ãªtre humain ne comprend ces flux en temps rÃ©el.  
Des flash crashs ont dÃ©jÃ  eu lieu (6 mai 2010, 3 janvier 2019).â¶  
Aucun responsable nâ€™a Ã©tÃ© identifiÃ©.  
Aucune rÃ©gulation nâ€™a Ã©tÃ© mise en place.  

Cette **opacitÃ© structurelle** nâ€™est pas un bug, câ€™est une propriÃ©tÃ© des systÃ¨mes trop complexes pour Ãªtre compris.  
Cela signifie que certains systÃ¨mes deviennent incomprÃ©hensibles non par volontÃ©, mais par consÃ©quence de leur complexitÃ© interne. Les rÃ©seaux de neurones profonds, par exemple, produisent des rÃ©sultats efficaces sans que lâ€™on puisse auditer facilement leurs mÃ©canismes. Ils fonctionnent, mais personne ne peut en rendre compte de maniÃ¨re transparente. Câ€™est un **risque majeur pour la gouvernance**.  

---

## 1.7 Conclusion du chapitre

La technologie nâ€™est pas un **ensemble dâ€™outils**, mais une **forme de mÃ©moire dÃ©lÃ©guÃ©e**.  
Elle permet la coordination sans comprÃ©hension, la division du travail sans fragmentation, la survie du savoir sans transmission explicite.  

Mais cette dÃ©lÃ©gation devient dangereuse quand elle Ã©chappe Ã  tout contrÃ´le collectif.  
Le **bon objet** est donc celui qui encapsule la complexitÃ© sans la verrouiller, qui dÃ©lÃ¨gue sans aliÃ©ner, qui survit Ã  son oubli sans devenir incontrÃ´lable.  

En termes politiques : un **bon objet** doit rester contrÃ´lable par la sociÃ©tÃ©, mÃªme aprÃ¨s des dÃ©cennies dâ€™usage. Il doit Ãªtre **rÃ©parable, auditable et contestable**.  

---

## ğŸ“Œ Notes de bas de page â€“ Chapitre 1

Â¹ Whitehead, A. N. (1929). Process and Reality, p. 42.  
Â² Sur la charrue comme objet technique culturel, voir Gille, B. (2000). Histoire des techniques, Fayard, p. 211-230.  
Â³ Ingold, T. (2000). The Perception of the Environment, Routledge, ch. 8.  
â´ Hayek, F. (1945). The Use of Knowledge in Society, American Economic Review, 35(4), p. 519-530.  
âµ Winner, L. (1980). Do Artifacts Have Politics?, Daedalus, 109(1), p. 121-136.  
â¶ Kirilenko, A. et al. (2017). The Flash Crash: High-Frequency Trading in an Electronic Market, Journal of Finance, 72(3), p. 967-998.  
â· Philippe Silberzahn, Â« Comment la technologie est la clÃ© de la civilisation crÃ©ative Â», blog philippesilberzahn.com, 10 mars 2025.  
â¸ Philippe Silberzahn, Â« Et si lâ€™artificiel Ã©tait notre vraie nature ? Â», blog philippesilberzahn.com, 24 juin 2024.

